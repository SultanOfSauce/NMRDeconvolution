{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2b89c8b5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import numpy.typing as npt\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import NMRAux as nmr\n",
    "\n",
    "from torchinfo import summary\n",
    "\n",
    "import torch as th\n",
    "import torch.nn as nn\n",
    "from torch.nn.functional import relu\n",
    "from torch import Tensor\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "#from torchvision.models import googlenet\n",
    "\n",
    "#from collections.abc import Callable\n",
    "from tqdm.notebook import trange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "19f810d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.04785747e-01,  3.00284668e-03,  1.03567415e+00, ...,\n",
       "         6.55396321e-02, -4.19977229e-01, -2.91674057e-01],\n",
       "       [ 4.37381808e-01,  7.46948189e-01,  3.14153511e-01, ...,\n",
       "         4.46124643e-01,  2.41310744e-01,  8.99329200e-01],\n",
       "       [ 3.27905708e-01,  2.25889366e-01, -5.71374760e-02, ...,\n",
       "         1.25497055e-01,  1.35160396e+00,  1.08981874e+00],\n",
       "       ...,\n",
       "       [ 1.21109686e+00,  1.78277372e+00,  1.70332264e+00, ...,\n",
       "         2.69508676e+00,  2.07795730e+00,  1.95479407e+00],\n",
       "       [ 2.62848639e+02,  7.53245730e+00,  2.59792528e+03, ...,\n",
       "         1.64402160e+02, -1.05348720e+03, -7.31646539e+02],\n",
       "       [ 6.59522763e+02,  1.88999535e+01,  6.51854567e+03, ...,\n",
       "         4.12507240e+02, -2.64334178e+03, -1.83580006e+03]],\n",
       "      shape=(10, 8192))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yy, yyF, yyR, res = nmr.generateRandomSpectrum()\n",
    "yy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "832184fc",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "x and y must have same first dimension, but have shapes (0,) and (8192,)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m fig, ax = plt.subplots(\u001b[32m3\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[43max\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mplot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnmr\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCSSubRange\u001b[49m\u001b[43m,\u001b[49m\u001b[43myy\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      3\u001b[39m ax[\u001b[32m1\u001b[39m].plot(nmr.CSSubRange,yyF[\u001b[32m0\u001b[39m])\n\u001b[32m      4\u001b[39m ax[\u001b[32m2\u001b[39m].plot(nmr.CSSubRange,yyR[\u001b[32m0\u001b[39m])\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pythonenvs/deeplearning/lib/python3.13/site-packages/matplotlib/axes/_axes.py:1777\u001b[39m, in \u001b[36mAxes.plot\u001b[39m\u001b[34m(self, scalex, scaley, data, *args, **kwargs)\u001b[39m\n\u001b[32m   1534\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1535\u001b[39m \u001b[33;03mPlot y versus x as lines and/or markers.\u001b[39;00m\n\u001b[32m   1536\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   1774\u001b[39m \u001b[33;03m(``'green'``) or hex strings (``'#008000'``).\u001b[39;00m\n\u001b[32m   1775\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1776\u001b[39m kwargs = cbook.normalize_kwargs(kwargs, mlines.Line2D)\n\u001b[32m-> \u001b[39m\u001b[32m1777\u001b[39m lines = [*\u001b[38;5;28mself\u001b[39m._get_lines(\u001b[38;5;28mself\u001b[39m, *args, data=data, **kwargs)]\n\u001b[32m   1778\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m lines:\n\u001b[32m   1779\u001b[39m     \u001b[38;5;28mself\u001b[39m.add_line(line)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pythonenvs/deeplearning/lib/python3.13/site-packages/matplotlib/axes/_base.py:297\u001b[39m, in \u001b[36m_process_plot_var_args.__call__\u001b[39m\u001b[34m(self, axes, data, return_kwargs, *args, **kwargs)\u001b[39m\n\u001b[32m    295\u001b[39m     this += args[\u001b[32m0\u001b[39m],\n\u001b[32m    296\u001b[39m     args = args[\u001b[32m1\u001b[39m:]\n\u001b[32m--> \u001b[39m\u001b[32m297\u001b[39m \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_plot_args\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    298\u001b[39m \u001b[43m    \u001b[49m\u001b[43maxes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mambiguous_fmt_datakey\u001b[49m\u001b[43m=\u001b[49m\u001b[43mambiguous_fmt_datakey\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    299\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_kwargs\u001b[49m\n\u001b[32m    300\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pythonenvs/deeplearning/lib/python3.13/site-packages/matplotlib/axes/_base.py:494\u001b[39m, in \u001b[36m_process_plot_var_args._plot_args\u001b[39m\u001b[34m(self, axes, tup, kwargs, return_kwargs, ambiguous_fmt_datakey)\u001b[39m\n\u001b[32m    491\u001b[39m     axes.yaxis.update_units(y)\n\u001b[32m    493\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m x.shape[\u001b[32m0\u001b[39m] != y.shape[\u001b[32m0\u001b[39m]:\n\u001b[32m--> \u001b[39m\u001b[32m494\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mx and y must have same first dimension, but \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    495\u001b[39m                      \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mhave shapes \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx.shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m and \u001b[39m\u001b[38;5;132;01m{\u001b[39;00my.shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    496\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m x.ndim > \u001b[32m2\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m y.ndim > \u001b[32m2\u001b[39m:\n\u001b[32m    497\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mx and y can be no greater than 2D, but have \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    498\u001b[39m                      \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mshapes \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx.shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m and \u001b[39m\u001b[38;5;132;01m{\u001b[39;00my.shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mValueError\u001b[39m: x and y must have same first dimension, but have shapes (0,) and (8192,)"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(3)\n",
    "ax[0].plot(nmr.CSSubRange,yy [0,:])\n",
    "ax[1].plot(nmr.CSSubRange,yyF[0,:])\n",
    "ax[2].plot(nmr.CSSubRange,yyR[0,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e8b03a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from https://github.com/antspy/inception_v1.pytorch/blob/master/inception_v1.py#L74\n",
    "class Inception_piece(nn.Module):\n",
    "    def __init__(self, kernel, out):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.kernel = kernel\n",
    "        self.out = out\n",
    "        \n",
    "        #mixed 'name'_bn\n",
    "        self.conv_bn = nn.LazyConv1d(out_channels=1,        kernel_size=self.kernel, stride=1, padding=self.kernel-1)\n",
    "        #mixed 'name'\n",
    "        self.conv    = nn.LazyConv1d(out_channels=self.out, kernel_size=self.kernel, stride=1, padding=0)\n",
    "        \n",
    "    def forward(self,input):\n",
    "        output = relu(self.conv_bn(input))\n",
    "        return relu(self.conv(output))\n",
    "\n",
    "class Inception_variant(nn.Module):\n",
    "    def __init__(self, depth_dim):\n",
    "        super().__init__()\n",
    "\n",
    "        self.depth_dim = depth_dim\n",
    "\n",
    "        #mixed 'name'_(2,16)_bn\n",
    "        self.conv_2_16 = Inception_piece(2,16)\n",
    "\n",
    "        #mixed 'name'_(4,32)_bn\n",
    "        self.conv_4_32 = Inception_piece(4,32)\n",
    "\n",
    "        #mixed 'name'_(8,64)_bn\n",
    "        self.conv_8_64 = Inception_piece(8,64)\n",
    "        \n",
    "        #mixed 'name'_(16,32)_bn\n",
    "        self.conv_16_32 = Inception_piece(16,32)\n",
    "        \n",
    "        #mixed 'name'_(64,8)_bn\n",
    "        self.conv_64_8 = Inception_piece(64,8)\n",
    "\n",
    "        self.max_pool_1 = nn.MaxPool1d(kernel_size=3, stride=1, padding=1)\n",
    "        #mixed 'name'_pool_reduce\n",
    "        self.conv_max_1 = nn.LazyConv1d(\n",
    "            out_channels=1, kernel_size=1, stride=1, padding=0)\n",
    "        \n",
    "    def forward(self, input):\n",
    "\n",
    "        output1 = self.conv_2_16(input)\n",
    "        output2 = self.conv_4_32(input)\n",
    "        output3 = self.conv_8_64(input)\n",
    "        output4 = self.conv_16_32(input)\n",
    "        output5 = self.conv_64_8(input)\n",
    "\n",
    "        output6 = relu(self.conv_max_1(self.max_pool_1(input)))\n",
    "\n",
    "        return th.transpose(\n",
    "            th.cat([output1, output2, output3, output4, output5, output6], dim=self.depth_dim),\n",
    "            0,1)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4b1107f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#From https://stackoverflow.com/a/61372646\n",
    "#self.tdd = nn.Conv2d(1, num_of_output_channels, (num_of_input_channels, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a947d6c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#From https://discuss.pytorch.org/t/any-pytorch-function-can-work-as-keras-timedistributed/1346/4\n",
    "class TimeDistributed(nn.Module):\n",
    "    def __init__(self, module, batch_first=False):\n",
    "        super(TimeDistributed, self).__init__()\n",
    "        self.module = module\n",
    "        self.batch_first = batch_first\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        if len(x.size()) <= 2:\n",
    "            return self.module(x)\n",
    "\n",
    "        # Squash samples and timesteps into a single axis\n",
    "        x_reshape = x.contiguous().view(-1, x.size(-1))  # (samples * timesteps, input_size)\n",
    "\n",
    "        y = self.module(x_reshape)\n",
    "\n",
    "        # We have to reshape Y\n",
    "        if self.batch_first:\n",
    "            y = y.contiguous().view(x.size(0), -1, y.size(-1))  # (samples, timesteps, output_size)\n",
    "        else:\n",
    "            y = y.view(-1, x.size(1), y.size(-1))  # (timesteps, samples, output_size)\n",
    "\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "bcca9e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#From https://stackoverflow.com/a/64265525\n",
    "class extract_tensor(nn.Module):\n",
    "    def forward(self,x):\n",
    "        # Output shape (batch, features, hidden)\n",
    "        tensor, _ = x\n",
    "        # Reshape shape (batch, hidden)\n",
    "        #return tensor[:, -1, :]\n",
    "        return tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "cfe5d76d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def NMRSeq() -> th.nn.Sequential:\n",
    "    return th.nn.Sequential(\n",
    "        \n",
    "        Inception_variant(0),\n",
    "        th.nn.ReLU(),\n",
    "        \n",
    "        TimeDistributed(module = th.nn.Linear(\n",
    "            in_features=153, out_features=64, bias=True\n",
    "        )),\n",
    "        \n",
    "        th.nn.ReLU(),\n",
    "        \n",
    "        TimeDistributed(module = th.nn.Linear(\n",
    "            in_features=64, out_features=32, bias=True\n",
    "        )),\n",
    "        th.nn.ReLU(),\n",
    "        nn.LSTM(32, 16, bidirectional=True),\n",
    "        extract_tensor(),\n",
    "        th.nn.ReLU(),\n",
    "        \n",
    "        TimeDistributed(module = th.nn.Linear(\n",
    "            in_features=32, out_features=32, bias=True\n",
    "        )),\n",
    "        th.nn.ReLU(),\n",
    "        \n",
    "        TimeDistributed(module = th.nn.Linear(\n",
    "            in_features=32, out_features=16, bias=True\n",
    "        )),\n",
    "        th.nn.ReLU(),\n",
    "        \n",
    "        TimeDistributed(module = th.nn.Linear(\n",
    "            in_features=16, out_features=1, bias=True\n",
    "        )),\n",
    "        th.nn.ReLU(),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "de4982b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's detect and select the most appropriate device\n",
    "# (adapt it to your specific hardware needs: mps, tpu, ...)\n",
    "device: th.device = th.device(\n",
    "    \"cuda\" if th.cuda.is_available() and DEVICE_AUTODETECT else \"cpu\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "eacd6a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NMRDataset(Dataset):\n",
    "    def __init__(self, maxLen = 250000, startSeed = 0):\n",
    "        self.maxLen = maxLen\n",
    "        self.startSeed = startSeed\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.maxLen\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        yy, yyF, yyR, res = nmr.generateRandomSpectrum(idx + self.startSeed)\n",
    "        isPk = np.full(len(nmr.CSRange), False)\n",
    "        isPk[res[3]] = True\n",
    "        return th.from_numpy(np.float32(yy)), isPk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "01daaaf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ML = 250000\n",
    "ML_test = 10000\n",
    "batch_size = 1\n",
    "train_set = NMRDataset(maxLen = ML)\n",
    "test_set = NMRDataset(maxLen = ML_test, startSeed = ML)\n",
    "\n",
    "train_loader: DataLoader = DataLoader(\n",
    "    dataset=train_set, batch_size=batch_size, shuffle=False\n",
    ")\n",
    "test_loader: DataLoader = DataLoader(\n",
    "    dataset=test_set,  batch_size=batch_size, shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "38a8027e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "Sequential                               [8192, 1]                 --\n",
       "├─Inception_variant: 1-1                 [8192, 153]               --\n",
       "│    └─Inception_piece: 2-1              [16, 8192]                --\n",
       "│    │    └─Conv1d: 3-1                  [1, 8193]                 3\n",
       "│    │    └─Conv1d: 3-2                  [16, 8192]                48\n",
       "│    └─Inception_piece: 2-2              [32, 8192]                --\n",
       "│    │    └─Conv1d: 3-3                  [1, 8195]                 5\n",
       "│    │    └─Conv1d: 3-4                  [32, 8192]                160\n",
       "│    └─Inception_piece: 2-3              [64, 8192]                --\n",
       "│    │    └─Conv1d: 3-5                  [1, 8199]                 9\n",
       "│    │    └─Conv1d: 3-6                  [64, 8192]                576\n",
       "│    └─Inception_piece: 2-4              [32, 8192]                --\n",
       "│    │    └─Conv1d: 3-7                  [1, 8207]                 17\n",
       "│    │    └─Conv1d: 3-8                  [32, 8192]                544\n",
       "│    └─Inception_piece: 2-5              [8, 8192]                 --\n",
       "│    │    └─Conv1d: 3-9                  [1, 8255]                 65\n",
       "│    │    └─Conv1d: 3-10                 [8, 8192]                 520\n",
       "│    └─MaxPool1d: 2-6                    [1, 8192]                 --\n",
       "│    └─Conv1d: 2-7                       [1, 8192]                 2\n",
       "├─ReLU: 1-2                              [8192, 153]               --\n",
       "├─TimeDistributed: 1-3                   [8192, 64]                --\n",
       "│    └─Linear: 2-8                       [8192, 64]                9,856\n",
       "├─ReLU: 1-4                              [8192, 64]                --\n",
       "├─TimeDistributed: 1-5                   [8192, 32]                --\n",
       "│    └─Linear: 2-9                       [8192, 32]                2,080\n",
       "├─ReLU: 1-6                              [8192, 32]                --\n",
       "├─LSTM: 1-7                              [8192, 32]                6,400\n",
       "├─extract_tensor: 1-8                    [8192, 32]                --\n",
       "├─ReLU: 1-9                              [8192, 32]                --\n",
       "├─TimeDistributed: 1-10                  [8192, 32]                --\n",
       "│    └─Linear: 2-10                      [8192, 32]                1,056\n",
       "├─ReLU: 1-11                             [8192, 32]                --\n",
       "├─TimeDistributed: 1-12                  [8192, 16]                --\n",
       "│    └─Linear: 2-11                      [8192, 16]                528\n",
       "├─ReLU: 1-13                             [8192, 16]                --\n",
       "├─TimeDistributed: 1-14                  [8192, 1]                 --\n",
       "│    └─Linear: 2-12                      [8192, 1]                 17\n",
       "├─ReLU: 1-15                             [8192, 1]                 --\n",
       "==========================================================================================\n",
       "Total params: 21,886\n",
       "Trainable params: 21,886\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.GIGABYTES): 1.79\n",
       "==========================================================================================\n",
       "Input size (MB): 0.03\n",
       "Forward/backward pass size (MB): 21.96\n",
       "Params size (MB): 0.09\n",
       "Estimated Total Size (MB): 22.08\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model: th.nn.Module = NMRSeq().to(device)\n",
    "summary(model, input_size=(batch_size, 8192))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "5ab71a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer: th.optim.Optimizer = th.optim.Adam(\n",
    "    params=model.parameters(), lr=0.001, weight_decay=0\n",
    ")\n",
    "\n",
    "#lossCriterion = nn.MSELoss()\n",
    "lossCriterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "a33475f2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31ce680887e24a7f894a4b914a28c108",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training epoch:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 8192]) torch.Size([1, 8192])\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Expected input batch_size (1) to match target batch_size (32).",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[59]\u001b[39m\u001b[32m, line 23\u001b[39m\n\u001b[32m     21\u001b[39m yhat = th.transpose(yhat,\u001b[32m0\u001b[39m,\u001b[32m1\u001b[39m)\n\u001b[32m     22\u001b[39m \u001b[38;5;28mprint\u001b[39m (y.shape, yhat.shape)\n\u001b[32m---> \u001b[39m\u001b[32m23\u001b[39m loss = \u001b[43mlossCriterion\u001b[49m\u001b[43m(\u001b[49m\u001b[43myhat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     25\u001b[39m \u001b[38;5;66;03m# Zero-out past gradients\u001b[39;00m\n\u001b[32m     26\u001b[39m optimizer.zero_grad()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pythonenvs/deeplearning/lib/python3.13/site-packages/torch/nn/modules/module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pythonenvs/deeplearning/lib/python3.13/site-packages/torch/nn/modules/module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pythonenvs/deeplearning/lib/python3.13/site-packages/torch/nn/modules/loss.py:1385\u001b[39m, in \u001b[36mCrossEntropyLoss.forward\u001b[39m\u001b[34m(self, input, target)\u001b[39m\n\u001b[32m   1383\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, target: Tensor) -> Tensor:\n\u001b[32m   1384\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Runs the forward pass.\"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1385\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcross_entropy\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1386\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1387\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1388\u001b[39m \u001b[43m        \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1389\u001b[39m \u001b[43m        \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1390\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreduction\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mreduction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1391\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1392\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pythonenvs/deeplearning/lib/python3.13/site-packages/torch/nn/functional.py:3458\u001b[39m, in \u001b[36mcross_entropy\u001b[39m\u001b[34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[39m\n\u001b[32m   3456\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m size_average \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m reduce \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   3457\u001b[39m     reduction = _Reduction.legacy_get_string(size_average, reduce)\n\u001b[32m-> \u001b[39m\u001b[32m3458\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_C\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_nn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcross_entropy_loss\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3459\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   3460\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3461\u001b[39m \u001b[43m    \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3462\u001b[39m \u001b[43m    \u001b[49m\u001b[43m_Reduction\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_enum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3463\u001b[39m \u001b[43m    \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3464\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3465\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mValueError\u001b[39m: Expected input batch_size (1) to match target batch_size (32)."
     ]
    }
   ],
   "source": [
    "EPOCHS = 100\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "eval_losses = []\n",
    "eval_acc = []\n",
    "test_acc = []\n",
    "\n",
    "# Loop over epochs\n",
    "for epoch in trange(EPOCHS, desc=\"Training epoch\"):\n",
    "\n",
    "    model.train()  # Remember to set the model in training mode before actual training\n",
    "\n",
    "    # Loop over data\n",
    "    for batch_idx, batched_datapoint in enumerate(train_loader):\n",
    "\n",
    "        x, y = batched_datapoint\n",
    "        x, y = x.to(device), y.to(device)\n",
    "\n",
    "        # Forward pass + loss computation\n",
    "        yhat = model(x)\n",
    "        yhat = th.transpose(yhat,0,1)\n",
    "        print (y.shape, yhat.shape)\n",
    "        loss = lossCriterion(yhat, y)\n",
    "\n",
    "        # Zero-out past gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "\n",
    "        # Update model parameters\n",
    "        optimizer.step()\n",
    "\n",
    "    model.eval()  # Remember to set the model in evaluation mode before evaluating it\n",
    "\n",
    "    # Since we are just evaluating the model, we don't need to compute gradients\n",
    "    with th.no_grad():\n",
    "        # ... by looping over training data again\n",
    "        for _, batched_datapoint_e in enumerate(train_loader):\n",
    "            x_e, y_e = batched_datapoint_e\n",
    "            x_e, y_e = x_e.to(device), y_e.to(device)\n",
    "            modeltarget_e = model(x_e)\n",
    "            ypred_e = th.argmax(modeltarget_e, dim=1, keepdim=True)\n",
    "            trackingmetric += lossCriterion(modeltarget_e, y_e).item()\n",
    "            trackingcorrect += ypred_e.eq(y_e.view_as(ypred_e)).sum().item()\n",
    "            num_elem += x_e.shape[0]\n",
    "        eval_losses.append(trackingmetric / num_elem)\n",
    "        eval_acc.append(trackingcorrect / num_elem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef79fea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "00dd96ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NMRModule(th.nn.Module):\n",
    "    def __init__(self, cls_out: int = 10) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        self.inception = Inception_variant(0)\n",
    "        \n",
    "        self.tddb1 = nn.Conv1d(1, \n",
    "                              64,#num_of_output_channels, \n",
    "                              (158, 1)) #num_of_input_channels\n",
    "        \n",
    "        self.tddb2 = nn.Conv1d(1, \n",
    "                              32,#num_of_output_channels, \n",
    "                              (64,  1)) #num_of_input_channels\n",
    "        \n",
    "        self.bdlstm = th.nn.LSTM(64, 16, bidirectional=True)\n",
    "        \n",
    "        self.tdda1 = nn.Conv1d(1, \n",
    "                              32,#num_of_output_channels, \n",
    "                              (16, 1))\n",
    "        \n",
    "        self.tdda2 = nn.Conv1d(1, \n",
    "                              16,#num_of_output_channels, \n",
    "                              (32, 1)) #num_of_input_channels\n",
    "        \n",
    "        self.tdda3 = nn.Conv1d(1, \n",
    "                              5,#num_of_output_channels, \n",
    "                              (16, 1)) #num_of_input_channels\n",
    "        \n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        \n",
    "        x_ = self.inception(x)  # Apply first linear transformation\n",
    "        x_ = th.nn.functional.relu(x_)  # Relu Not Necessary?\n",
    "        \n",
    "        x_ = self.tddb1(x_)\n",
    "        x_ = relu(x_)\n",
    "        \n",
    "        x_ = self.tddb2(x_)\n",
    "        x_ = relu(x_)\n",
    "        \n",
    "        x_ = self.bdlstm(x_)\n",
    "        x_ = relu(x_)\n",
    "        \n",
    "        x_ = self.tdd11(x_)\n",
    "        x_ = relu(x_)\n",
    "        \n",
    "        x_ = self.tdda2(x_)\n",
    "        x_ = relu(x_)\n",
    "        \n",
    "        x_ = self.tdda3(x_)\n",
    "        x_ = relu(x_)\n",
    "        \n",
    "        \n",
    "        # N.B.: outputs are [-inf, +inf]; e.g. to be used as logits\n",
    "        return x_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deeplearning",
   "language": "python",
   "name": "deeplearning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
