{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2b89c8b5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import numpy.typing as npt\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import NMRAux as nmr\n",
    "\n",
    "from torchinfo import summary\n",
    "\n",
    "import torch as th\n",
    "import torch.nn as nn\n",
    "from torch.nn.functional import relu\n",
    "from torch import Tensor\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "#from torchvision.models import googlenet\n",
    "\n",
    "#from collections.abc import Callable\n",
    "from tqdm.notebook import trange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "832184fc",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.pythonenvs/deeplearning/lib/python3.13/site-packages/nmrglue/process/proc_base.py:938: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "  ).astype(data.dtype)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7fa56dce8c20>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "yy, res = nmr.generateRandomSpectrum()\n",
    "fig, ax = plt.subplots(figsize=(8, 2))\n",
    "ax.plot(yy[\"true\"])\n",
    "ax.scatter(res,[yy[\"pure\"][i] for i in res], c = \"orange\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e8b03a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from https://github.com/antspy/inception_v1.pytorch/blob/master/inception_v1.py#L74\n",
    "class Inception_piece(nn.Module):\n",
    "    def __init__(self, kernel, out):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.kernel = kernel\n",
    "        self.out = out\n",
    "        \n",
    "        #mixed 'name'_bn\n",
    "        self.conv_bn = nn.LazyConv1d(out_channels=1,        kernel_size=self.kernel, stride=1, padding=self.kernel-1)\n",
    "        #mixed 'name'\n",
    "        self.conv    = nn.LazyConv1d(out_channels=self.out, kernel_size=self.kernel, stride=1, padding=0)\n",
    "        \n",
    "    def forward(self,input):\n",
    "        output = relu(self.conv_bn(input))\n",
    "        return relu(self.conv(output))\n",
    "\n",
    "class Inception_variant(nn.Module):\n",
    "    def __init__(self, depth_dim):\n",
    "        super().__init__()\n",
    "\n",
    "        self.depth_dim = depth_dim\n",
    "\n",
    "        #mixed 'name'_(2,16)_bn\n",
    "        self.conv_2_16 = Inception_piece(2,16)\n",
    "\n",
    "        #mixed 'name'_(4,32)_bn\n",
    "        self.conv_4_32 = Inception_piece(4,32)\n",
    "\n",
    "        #mixed 'name'_(8,64)_bn\n",
    "        self.conv_8_64 = Inception_piece(8,64)\n",
    "        \n",
    "        #mixed 'name'_(16,32)_bn\n",
    "        self.conv_16_32 = Inception_piece(16,32)\n",
    "        \n",
    "        #mixed 'name'_(64,8)_bn\n",
    "        self.conv_64_8 = Inception_piece(64,8)\n",
    "\n",
    "        self.max_pool_1 = nn.MaxPool1d(kernel_size=3, stride=1, padding=1)\n",
    "        #mixed 'name'_pool_reduce\n",
    "        self.conv_max_1 = nn.LazyConv1d(\n",
    "            out_channels=1, kernel_size=1, stride=1, padding=0)\n",
    "        \n",
    "    def forward(self, input):\n",
    "\n",
    "        output1 = self.conv_2_16(input)\n",
    "        output2 = self.conv_4_32(input)\n",
    "        output3 = self.conv_8_64(input)\n",
    "        output4 = self.conv_16_32(input)\n",
    "        output5 = self.conv_64_8(input)\n",
    "\n",
    "        output6 = relu(self.conv_max_1(self.max_pool_1(input)))\n",
    "\n",
    "        c = th.cat([output1, output2, output3, output4, output5, output6], dim=self.depth_dim)\n",
    "        return th.transpose(c,0,1)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "97a6b5b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from https://github.com/antspy/inception_v1.pytorch/blob/master/inception_v1.py#L74\n",
    "class Inception_test(nn.Module):\n",
    "    def __init__(self, kernel, out):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.kernel = kernel\n",
    "        self.out = out\n",
    "        \n",
    "        #mixed 'name'_bn\n",
    "        self.conv_bn = nn.LazyConv1d(out_channels=1,        kernel_size=self.kernel, stride=1, padding=self.kernel-1)\n",
    "        #mixed 'name'\n",
    "        self.conv    = nn.LazyConv1d(out_channels=self.out, kernel_size=self.kernel, stride=1, padding=0)\n",
    "        \n",
    "    def forward(self,input):\n",
    "        output = relu(self.conv_bn(input))\n",
    "        return relu(self.conv(output))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4b1107f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#From https://stackoverflow.com/a/61372646\n",
    "#self.tdd = nn.Conv2d(1, num_of_output_channels, (num_of_input_channels, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a947d6c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#From https://discuss.pytorch.org/t/any-pytorch-function-can-work-as-keras-timedistributed/1346/4\n",
    "class TimeDistributed(nn.Module):\n",
    "    def __init__(self, module, batch_first=False):\n",
    "        super(TimeDistributed, self).__init__()\n",
    "        self.module = module\n",
    "        self.batch_first = batch_first\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        if len(x.size()) <= 2:\n",
    "            return self.module(x)\n",
    "\n",
    "        # Squash samples and timesteps into a single axis\n",
    "        x_reshape = x.contiguous().view(-1, x.size(-1))  # (samples * timesteps, input_size)\n",
    "\n",
    "        y = self.module(x_reshape)\n",
    "\n",
    "        # We have to reshape Y\n",
    "        if self.batch_first:\n",
    "            y = y.contiguous().view(x.size(0), -1, y.size(-1))  # (samples, timesteps, output_size)\n",
    "        else:\n",
    "            y = y.view(-1, x.size(1), y.size(-1))  # (timesteps, samples, output_size)\n",
    "\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bcca9e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#From https://stackoverflow.com/a/64265525\n",
    "class extract_tensor(nn.Module):\n",
    "    def forward(self,x):\n",
    "        # Output shape (batch, features, hidden)\n",
    "        tensor, _ = x\n",
    "        # Reshape shape (batch, hidden)\n",
    "        #return tensor[:, -1, :]\n",
    "        return tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cfe5d76d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def NMRSeq() -> th.nn.Sequential:\n",
    "    return th.nn.Sequential(\n",
    "        \n",
    "        Inception_variant(0),\n",
    "        #Inception_test(3, 153),\n",
    "        th.nn.ReLU(),\n",
    "        \n",
    "        th.nn.Linear(\n",
    "            in_features=153, out_features=64, bias=True\n",
    "        ),\n",
    "        \n",
    "        th.nn.ReLU(),\n",
    "        \n",
    "        th.nn.Linear(\n",
    "            in_features=64, out_features=32, bias=True\n",
    "        ),\n",
    "        th.nn.ReLU(),\n",
    "        nn.LSTM(32, 16, bidirectional=True),\n",
    "        extract_tensor(),\n",
    "        th.nn.ReLU(),\n",
    "        \n",
    "        th.nn.Linear(\n",
    "            in_features=32, out_features=32, bias=True\n",
    "        ),\n",
    "        th.nn.ReLU(),\n",
    "        \n",
    "        th.nn.Linear(\n",
    "            in_features=32, out_features=16, bias=True\n",
    "        ),\n",
    "        th.nn.ReLU(),\n",
    "        \n",
    "        th.nn.Linear(\n",
    "            in_features=16, out_features=1, bias=True\n",
    "        ),\n",
    "        th.nn.ReLU(),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "de4982b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's detect and select the most appropriate device\n",
    "# (adapt it to your specific hardware needs: mps, tpu, ...)\n",
    "device: th.device = th.device(\n",
    "    \"cuda\" if th.cuda.is_available() and DEVICE_AUTODETECT else \"cpu\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eacd6a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NMRDataset(Dataset):\n",
    "    def __init__(self, maxLen = 250000, startSeed = 0):\n",
    "        self.maxLen = maxLen\n",
    "        self.startSeed = startSeed\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.maxLen\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        yy, res = nmr.generateRandomSpectrum(idx + self.startSeed)\n",
    "        isPk = np.full_like(yy[\"true\"], False)\n",
    "        for i in res:\n",
    "            isPk[i] = True\n",
    "        \n",
    "        #isPk[res[]] = True\n",
    "        return th.from_numpy(np.float32(yy[\"true\"])), isPk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "01daaaf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ML = 250000\n",
    "ML_test = 10000\n",
    "batch_size = 1\n",
    "train_set = NMRDataset(maxLen = ML)\n",
    "test_set = NMRDataset(maxLen = ML_test, startSeed = ML)\n",
    "\n",
    "train_loader: DataLoader = DataLoader(\n",
    "    dataset=train_set, batch_size=batch_size, shuffle=False\n",
    ")\n",
    "test_loader: DataLoader = DataLoader(\n",
    "    dataset=test_set,  batch_size=batch_size, shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "38a8027e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "Sequential                               [8192, 1]                 --\n",
       "├─Inception_variant: 1-1                 [8192, 153]               --\n",
       "│    └─Inception_piece: 2-1              [16, 8192]                --\n",
       "│    │    └─Conv1d: 3-1                  [1, 8193]                 3\n",
       "│    │    └─Conv1d: 3-2                  [16, 8192]                48\n",
       "│    └─Inception_piece: 2-2              [32, 8192]                --\n",
       "│    │    └─Conv1d: 3-3                  [1, 8195]                 5\n",
       "│    │    └─Conv1d: 3-4                  [32, 8192]                160\n",
       "│    └─Inception_piece: 2-3              [64, 8192]                --\n",
       "│    │    └─Conv1d: 3-5                  [1, 8199]                 9\n",
       "│    │    └─Conv1d: 3-6                  [64, 8192]                576\n",
       "│    └─Inception_piece: 2-4              [32, 8192]                --\n",
       "│    │    └─Conv1d: 3-7                  [1, 8207]                 17\n",
       "│    │    └─Conv1d: 3-8                  [32, 8192]                544\n",
       "│    └─Inception_piece: 2-5              [8, 8192]                 --\n",
       "│    │    └─Conv1d: 3-9                  [1, 8255]                 65\n",
       "│    │    └─Conv1d: 3-10                 [8, 8192]                 520\n",
       "│    └─MaxPool1d: 2-6                    [1, 8192]                 --\n",
       "│    └─Conv1d: 2-7                       [1, 8192]                 2\n",
       "├─ReLU: 1-2                              [8192, 153]               --\n",
       "├─Linear: 1-3                            [8192, 64]                9,856\n",
       "├─ReLU: 1-4                              [8192, 64]                --\n",
       "├─Linear: 1-5                            [8192, 32]                2,080\n",
       "├─ReLU: 1-6                              [8192, 32]                --\n",
       "├─LSTM: 1-7                              [8192, 32]                6,400\n",
       "├─extract_tensor: 1-8                    [8192, 32]                --\n",
       "├─ReLU: 1-9                              [8192, 32]                --\n",
       "├─Linear: 1-10                           [8192, 32]                1,056\n",
       "├─ReLU: 1-11                             [8192, 32]                --\n",
       "├─Linear: 1-12                           [8192, 16]                528\n",
       "├─ReLU: 1-13                             [8192, 16]                --\n",
       "├─Linear: 1-14                           [8192, 1]                 17\n",
       "├─ReLU: 1-15                             [8192, 1]                 --\n",
       "==========================================================================================\n",
       "Total params: 21,886\n",
       "Trainable params: 21,886\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.GIGABYTES): 1.79\n",
       "==========================================================================================\n",
       "Input size (MB): 0.03\n",
       "Forward/backward pass size (MB): 21.96\n",
       "Params size (MB): 0.09\n",
       "Estimated Total Size (MB): 22.08\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model: th.nn.Module = NMRSeq().to(device)\n",
    "summary(model, input_size=(1,8192))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5ab71a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer: th.optim.Optimizer = th.optim.Adam(\n",
    "    params=model.parameters(), lr=0.001, weight_decay=0\n",
    ")\n",
    "\n",
    "#lossCriterion = nn.MSELoss()\n",
    "lossCriterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a33475f2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9bbd576bda59473f81fdab127e7a6b43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training epoch:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.pythonenvs/deeplearning/lib/python3.13/site-packages/nmrglue/process/proc_base.py:938: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "  ).astype(data.dtype)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 8192]) torch.Size([1, 8192])\n",
      "torch.Size([1, 8192]) torch.Size([1, 8192])\n",
      "torch.Size([1, 8192]) torch.Size([1, 8192])\n",
      "torch.Size([1, 8192]) torch.Size([1, 8192])\n",
      "torch.Size([1, 8192]) torch.Size([1, 8192])\n",
      "torch.Size([1, 8192]) torch.Size([1, 8192])\n",
      "torch.Size([1, 8192]) torch.Size([1, 8192])\n",
      "torch.Size([1, 8192]) torch.Size([1, 8192])\n",
      "torch.Size([1, 8192]) torch.Size([1, 8192])\n",
      "torch.Size([1, 8192]) torch.Size([1, 8192])\n",
      "torch.Size([1, 8192]) torch.Size([1, 8192])\n",
      "torch.Size([1, 8192]) torch.Size([1, 8192])\n",
      "torch.Size([1, 8192]) torch.Size([1, 8192])\n",
      "torch.Size([1, 8192]) torch.Size([1, 8192])\n",
      "torch.Size([1, 8192]) torch.Size([1, 8192])\n",
      "torch.Size([1, 8192]) torch.Size([1, 8192])\n",
      "torch.Size([1, 8192]) torch.Size([1, 8192])\n",
      "torch.Size([1, 8192]) torch.Size([1, 8192])\n",
      "torch.Size([1, 8192]) torch.Size([1, 8192])\n",
      "torch.Size([1, 8192]) torch.Size([1, 8192])\n",
      "torch.Size([1, 8192]) torch.Size([1, 8192])\n",
      "torch.Size([1, 8192]) torch.Size([1, 8192])\n",
      "torch.Size([1, 8192]) torch.Size([1, 8192])\n",
      "torch.Size([1, 8192]) torch.Size([1, 8192])\n",
      "torch.Size([1, 8192]) torch.Size([1, 8192])\n",
      "torch.Size([1, 8192]) torch.Size([1, 8192])\n",
      "torch.Size([1, 8192]) torch.Size([1, 8192])\n",
      "torch.Size([1, 8192]) torch.Size([1, 8192])\n",
      "torch.Size([1, 8192]) torch.Size([1, 8192])\n",
      "torch.Size([1, 8192]) torch.Size([1, 8192])\n",
      "torch.Size([1, 8192]) torch.Size([1, 8192])\n",
      "torch.Size([1, 8192]) torch.Size([1, 8192])\n",
      "torch.Size([1, 8192]) torch.Size([1, 8192])\n",
      "torch.Size([1, 8192]) torch.Size([1, 8192])\n",
      "torch.Size([1, 8192]) torch.Size([1, 8192])\n",
      "torch.Size([1, 8192]) torch.Size([1, 8192])\n",
      "torch.Size([1, 8192]) torch.Size([1, 8192])\n",
      "torch.Size([1, 8192]) torch.Size([1, 8192])\n",
      "torch.Size([1, 8192]) torch.Size([1, 8192])\n",
      "torch.Size([1, 8192]) torch.Size([1, 8192])\n",
      "torch.Size([1, 8192]) torch.Size([1, 8192])\n",
      "torch.Size([1, 8192]) torch.Size([1, 8192])\n",
      "torch.Size([1, 8192]) torch.Size([1, 8192])\n",
      "torch.Size([1, 8192]) torch.Size([1, 8192])\n",
      "torch.Size([1, 8192]) torch.Size([1, 8192])\n",
      "torch.Size([1, 8192]) torch.Size([1, 8192])\n",
      "torch.Size([1, 8192]) torch.Size([1, 8192])\n",
      "torch.Size([1, 8192]) torch.Size([1, 8192])\n",
      "torch.Size([1, 8192]) torch.Size([1, 8192])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 14\u001b[39m\n\u001b[32m     11\u001b[39m model.train()  \u001b[38;5;66;03m# Remember to set the model in training mode before actual training\u001b[39;00m\n\u001b[32m     13\u001b[39m \u001b[38;5;66;03m# Loop over data\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatched_datapoint\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     16\u001b[39m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatched_datapoint\u001b[49m\n\u001b[32m     17\u001b[39m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pythonenvs/deeplearning/lib/python3.13/site-packages/torch/utils/data/dataloader.py:732\u001b[39m, in \u001b[36m_BaseDataLoaderIter.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    729\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    730\u001b[39m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[32m    731\u001b[39m     \u001b[38;5;28mself\u001b[39m._reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m732\u001b[39m data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    733\u001b[39m \u001b[38;5;28mself\u001b[39m._num_yielded += \u001b[32m1\u001b[39m\n\u001b[32m    734\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    735\u001b[39m     \u001b[38;5;28mself\u001b[39m._dataset_kind == _DatasetKind.Iterable\n\u001b[32m    736\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    737\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._num_yielded > \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called\n\u001b[32m    738\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pythonenvs/deeplearning/lib/python3.13/site-packages/torch/utils/data/dataloader.py:788\u001b[39m, in \u001b[36m_SingleProcessDataLoaderIter._next_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    786\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    787\u001b[39m     index = \u001b[38;5;28mself\u001b[39m._next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m788\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m    789\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._pin_memory:\n\u001b[32m    790\u001b[39m         data = _utils.pin_memory.pin_memory(data, \u001b[38;5;28mself\u001b[39m._pin_memory_device)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pythonenvs/deeplearning/lib/python3.13/site-packages/torch/utils/data/_utils/fetch.py:52\u001b[39m, in \u001b[36m_MapDatasetFetcher.fetch\u001b[39m\u001b[34m(self, possibly_batched_index)\u001b[39m\n\u001b[32m     50\u001b[39m         data = \u001b[38;5;28mself\u001b[39m.dataset.__getitems__(possibly_batched_index)\n\u001b[32m     51\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m52\u001b[39m         data = [\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[32m     53\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     54\u001b[39m     data = \u001b[38;5;28mself\u001b[39m.dataset[possibly_batched_index]\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 10\u001b[39m, in \u001b[36mNMRDataset.__getitem__\u001b[39m\u001b[34m(self, idx)\u001b[39m\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, idx):\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m     yy, res = \u001b[43mnmr\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgenerateRandomSpectrum\u001b[49m\u001b[43m(\u001b[49m\u001b[43midx\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstartSeed\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     11\u001b[39m     isPk = np.full_like(yy[\u001b[33m\"\u001b[39m\u001b[33mtrue\u001b[39m\u001b[33m\"\u001b[39m], \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m     12\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m res:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/notebooks/NMR/NMRAux.py:144\u001b[39m, in \u001b[36mgenerateRandomSpectrum\u001b[39m\u001b[34m(seed)\u001b[39m\n\u001b[32m    141\u001b[39m SNR = yy/(maxNoise/\u001b[32m2\u001b[39m)      \n\u001b[32m    142\u001b[39m yyReg = yy * peakShrinking(SNR)\n\u001b[32m--> \u001b[39m\u001b[32m144\u001b[39m yyFiltered = \u001b[43mdynamicScaleFiltering\u001b[49m\u001b[43m(\u001b[49m\u001b[43myy\u001b[49m\u001b[43m)\u001b[49m  \n\u001b[32m    146\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m'''\u001b[39;00m\n\u001b[32m    147\u001b[39m \u001b[33;03m\u001b[39;00m\n\u001b[32m    148\u001b[39m \u001b[33;03m    \u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    157\u001b[39m \u001b[33;03mretStats.append({\"xPks\": xPks, \"yPks\":yPks, \"wPks\": wPks, \"peaks\": peaks})\u001b[39;00m\n\u001b[32m    158\u001b[39m \u001b[33;03m'''\u001b[39;00m\n\u001b[32m    161\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[33m\"\u001b[39m\u001b[33mpure\u001b[39m\u001b[33m\"\u001b[39m: yy, \u001b[33m\"\u001b[39m\u001b[33mtrue\u001b[39m\u001b[33m\"\u001b[39m: yy + noise, \u001b[33m\"\u001b[39m\u001b[33mfiltered\u001b[39m\u001b[33m\"\u001b[39m: yyFiltered, \u001b[33m\"\u001b[39m\u001b[33mreg\u001b[39m\u001b[33m\"\u001b[39m: yyReg}, peaks\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/notebooks/NMR/NMRAux.py:49\u001b[39m, in \u001b[36mdynamicScaleFiltering\u001b[39m\u001b[34m(yy)\u001b[39m\n\u001b[32m     47\u001b[39m     S_min = minimum_filter1d(yy, k)\n\u001b[32m     48\u001b[39m     S_min_g = gaussian_filter1d(S_min, k, mode = \u001b[33m\"\u001b[39m\u001b[33mmirror\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m49\u001b[39m     S_max_g = \u001b[43mgaussian_filter1d\u001b[49m\u001b[43m(\u001b[49m\u001b[43mS_max\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmirror\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     50\u001b[39m     yy_final += (yy - S_min_g) / (S_max_g - S_min_g)\n\u001b[32m     51\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m yy_final / \u001b[38;5;28mlen\u001b[39m(kernelSizes)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pythonenvs/deeplearning/lib/python3.13/site-packages/scipy/ndimage/_filters.py:753\u001b[39m, in \u001b[36mgaussian_filter1d\u001b[39m\u001b[34m(input, sigma, axis, order, output, mode, cval, truncate, radius)\u001b[39m\n\u001b[32m    751\u001b[39m \u001b[38;5;66;03m# Since we are calling correlate, not convolve, revert the kernel\u001b[39;00m\n\u001b[32m    752\u001b[39m weights = _gaussian_kernel1d(sigma, order, lw)[::-\u001b[32m1\u001b[39m]\n\u001b[32m--> \u001b[39m\u001b[32m753\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcorrelate1d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pythonenvs/deeplearning/lib/python3.13/site-packages/scipy/ndimage/_filters.py:610\u001b[39m, in \u001b[36mcorrelate1d\u001b[39m\u001b[34m(input, weights, axis, output, mode, cval, origin)\u001b[39m\n\u001b[32m    606\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m'\u001b[39m\u001b[33mInvalid origin; origin must satisfy \u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m    607\u001b[39m                      \u001b[33m'\u001b[39m\u001b[33m-(len(weights) // 2) <= origin <= \u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m    608\u001b[39m                      \u001b[33m'\u001b[39m\u001b[33m(len(weights)-1) // 2\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m    609\u001b[39m mode = _ni_support._extend_mode_to_code(mode)\n\u001b[32m--> \u001b[39m\u001b[32m610\u001b[39m \u001b[43m_nd_image\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcorrelate1d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    611\u001b[39m \u001b[43m                      \u001b[49m\u001b[43morigin\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    612\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m output\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "EPOCHS = 100\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "eval_losses = []\n",
    "eval_acc = []\n",
    "test_acc = []\n",
    "\n",
    "# Loop over epochs\n",
    "for epoch in trange(EPOCHS, desc=\"Training epoch\"):\n",
    "\n",
    "    model.train()  # Remember to set the model in training mode before actual training\n",
    "\n",
    "    # Loop over data\n",
    "    for batch_idx, batched_datapoint in enumerate(train_loader):\n",
    "\n",
    "        x, y = batched_datapoint\n",
    "        x, y = x.to(device), y.to(device)\n",
    "\n",
    "        # Forward pass + loss computation\n",
    "        yhat = model(x)\n",
    "        yhat = th.transpose(yhat,0,1)\n",
    "        loss = lossCriterion(yhat, y)\n",
    "\n",
    "        # Zero-out past gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "\n",
    "        # Update model parameters\n",
    "        optimizer.step()\n",
    "\n",
    "    model.eval()  # Remember to set the model in evaluation mode before evaluating it\n",
    "\n",
    "    # Since we are just evaluating the model, we don't need to compute gradients\n",
    "    with th.no_grad():\n",
    "        # ... by looping over training data again\n",
    "        for _, batched_datapoint_e in enumerate(train_loader):\n",
    "            x_e, y_e = batched_datapoint_e\n",
    "            x_e, y_e = x_e.to(device), y_e.to(device)\n",
    "            modeltarget_e = model(x_e)\n",
    "            ypred_e = th.argmax(modeltarget_e, dim=1, keepdim=True)\n",
    "            trackingmetric += lossCriterion(modeltarget_e, y_e).item()\n",
    "            trackingcorrect += ypred_e.eq(y_e.view_as(ypred_e)).sum().item()\n",
    "            num_elem += x_e.shape[0]\n",
    "        eval_losses.append(trackingmetric / num_elem)\n",
    "        eval_acc.append(trackingcorrect / num_elem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef79fea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "00dd96ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NMRModule(th.nn.Module):\n",
    "    def __init__(self, cls_out: int = 10) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        self.inception = Inception_variant(0)\n",
    "        \n",
    "        self.tddb1 = nn.Conv1d(1, \n",
    "                              64,#num_of_output_channels, \n",
    "                              (158, 1)) #num_of_input_channels\n",
    "        \n",
    "        self.tddb2 = nn.Conv1d(1, \n",
    "                              32,#num_of_output_channels, \n",
    "                              (64,  1)) #num_of_input_channels\n",
    "        \n",
    "        self.bdlstm = th.nn.LSTM(64, 16, bidirectional=True)\n",
    "        \n",
    "        self.tdda1 = nn.Conv1d(1, \n",
    "                              32,#num_of_output_channels, \n",
    "                              (16, 1))\n",
    "        \n",
    "        self.tdda2 = nn.Conv1d(1, \n",
    "                              16,#num_of_output_channels, \n",
    "                              (32, 1)) #num_of_input_channels\n",
    "        \n",
    "        self.tdda3 = nn.Conv1d(1, \n",
    "                              5,#num_of_output_channels, \n",
    "                              (16, 1)) #num_of_input_channels\n",
    "        \n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        \n",
    "        x_ = self.inception(x)  # Apply first linear transformation\n",
    "        x_ = th.nn.functional.relu(x_)  # Relu Not Necessary?\n",
    "        \n",
    "        x_ = self.tddb1(x_)\n",
    "        x_ = relu(x_)\n",
    "        \n",
    "        x_ = self.tddb2(x_)\n",
    "        x_ = relu(x_)\n",
    "        \n",
    "        x_ = self.bdlstm(x_)\n",
    "        x_ = relu(x_)\n",
    "        \n",
    "        x_ = self.tdd11(x_)\n",
    "        x_ = relu(x_)\n",
    "        \n",
    "        x_ = self.tdda2(x_)\n",
    "        x_ = relu(x_)\n",
    "        \n",
    "        x_ = self.tdda3(x_)\n",
    "        x_ = relu(x_)\n",
    "        \n",
    "        \n",
    "        # N.B.: outputs are [-inf, +inf]; e.g. to be used as logits\n",
    "        return x_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deeplearning",
   "language": "python",
   "name": "deeplearning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
