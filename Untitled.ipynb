{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2b89c8b5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import numpy.typing as npt\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import NMRAux as nmr\n",
    "\n",
    "from torchinfo import summary\n",
    "\n",
    "import torch as th\n",
    "import torch.nn as nn\n",
    "from torch.nn.functional import relu\n",
    "from torch import Tensor\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "#from torchvision.models import googlenet\n",
    "\n",
    "#from collections.abc import Callable\n",
    "from tqdm.notebook import trange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "832184fc",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7fe85e272ad0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "yy, res = nmr.generateRandomSpectrum()\n",
    "fig, ax = plt.subplots(figsize=(8, 2))\n",
    "ax.plot(yy[\"true\"])\n",
    "ax.scatter(res,[yy[\"pure\"][i] for i in res], c = \"orange\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e8b03a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from https://github.com/antspy/inception_v1.pytorch/blob/master/inception_v1.py#L74\n",
    "class Inception_piece(nn.Module):\n",
    "    def __init__(self, kernel, out):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.kernel = kernel\n",
    "        self.out = out\n",
    "        \n",
    "        #mixed 'name'_bn\n",
    "        self.conv_bn = nn.LazyConv1d(out_channels=1,        kernel_size=self.kernel, stride=1, padding=self.kernel-1)\n",
    "        #mixed 'name'\n",
    "        self.conv    = nn.LazyConv1d(out_channels=self.out, kernel_size=self.kernel, stride=1, padding=0)\n",
    "        \n",
    "    def forward(self,input):\n",
    "        output = relu(self.conv_bn(input))\n",
    "        return relu(self.conv(output))\n",
    "\n",
    "class Inception_variant(nn.Module):\n",
    "    def __init__(self, depth_dim):\n",
    "        super().__init__()\n",
    "\n",
    "        self.depth_dim = depth_dim\n",
    "\n",
    "        #mixed 'name'_(2,16)_bn\n",
    "        self.conv_2_16 = Inception_piece(2,16)\n",
    "\n",
    "        #mixed 'name'_(4,32)_bn\n",
    "        self.conv_4_32 = Inception_piece(4,32)\n",
    "\n",
    "        #mixed 'name'_(8,64)_bn\n",
    "        self.conv_8_64 = Inception_piece(8,64)\n",
    "        \n",
    "        #mixed 'name'_(16,32)_bn\n",
    "        self.conv_16_32 = Inception_piece(16,32)\n",
    "        \n",
    "        #mixed 'name'_(64,8)_bn\n",
    "        self.conv_64_8 = Inception_piece(64,8)\n",
    "\n",
    "        self.max_pool_1 = nn.MaxPool1d(kernel_size=3, stride=1, padding=1)\n",
    "        #mixed 'name'_pool_reduce\n",
    "        self.conv_max_1 = nn.LazyConv1d(\n",
    "            out_channels=1, kernel_size=1, stride=1, padding=0)\n",
    "        \n",
    "    def forward(self, input):\n",
    "\n",
    "        output1 = self.conv_2_16(input)\n",
    "        output2 = self.conv_4_32(input)\n",
    "        output3 = self.conv_8_64(input)\n",
    "        output4 = self.conv_16_32(input)\n",
    "        output5 = self.conv_64_8(input)\n",
    "\n",
    "        output6 = relu(self.conv_max_1(self.max_pool_1(input)))\n",
    "\n",
    "        c = th.cat([output1, output2, output3, output4, output5, output6], dim=self.depth_dim)\n",
    "        return th.transpose(c,0,1)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "97a6b5b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from https://github.com/antspy/inception_v1.pytorch/blob/master/inception_v1.py#L74\n",
    "class Inception_test(nn.Module):\n",
    "    def __init__(self, kernel, out):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.kernel = kernel\n",
    "        self.out = out\n",
    "        \n",
    "        #mixed 'name'_bn\n",
    "        self.conv_bn = nn.LazyConv1d(out_channels=1,        kernel_size=self.kernel, stride=1, padding=self.kernel-1)\n",
    "        #mixed 'name'\n",
    "        self.conv    = nn.LazyConv1d(out_channels=self.out, kernel_size=self.kernel, stride=1, padding=0)\n",
    "        \n",
    "    def forward(self,input):\n",
    "        output = relu(self.conv_bn(input))\n",
    "        return relu(self.conv(output))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4b1107f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#From https://stackoverflow.com/a/61372646\n",
    "#self.tdd = nn.Conv2d(1, num_of_output_channels, (num_of_input_channels, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a947d6c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#From https://discuss.pytorch.org/t/any-pytorch-function-can-work-as-keras-timedistributed/1346/4\n",
    "class TimeDistributed(nn.Module):\n",
    "    def __init__(self, module, batch_first=False):\n",
    "        super(TimeDistributed, self).__init__()\n",
    "        self.module = module\n",
    "        self.batch_first = batch_first\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        if len(x.size()) <= 2:\n",
    "            return self.module(x)\n",
    "\n",
    "        # Squash samples and timesteps into a single axis\n",
    "        x_reshape = x.contiguous().view(-1, x.size(-1))  # (samples * timesteps, input_size)\n",
    "\n",
    "        y = self.module(x_reshape)\n",
    "\n",
    "        # We have to reshape Y\n",
    "        if self.batch_first:\n",
    "            y = y.contiguous().view(x.size(0), -1, y.size(-1))  # (samples, timesteps, output_size)\n",
    "        else:\n",
    "            y = y.view(-1, x.size(1), y.size(-1))  # (timesteps, samples, output_size)\n",
    "\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bcca9e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#From https://stackoverflow.com/a/64265525\n",
    "class extract_tensor(nn.Module):\n",
    "    def forward(self,x):\n",
    "        # Output shape (batch, features, hidden)\n",
    "        tensor, _ = x\n",
    "        # Reshape shape (batch, hidden)\n",
    "        #return tensor[:, -1, :]\n",
    "        return tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cfe5d76d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def NMRSeq() -> th.nn.Sequential:\n",
    "    return th.nn.Sequential(\n",
    "        \n",
    "        Inception_variant(0),\n",
    "        #Inception_test(3, 153),\n",
    "        th.nn.ReLU(),\n",
    "        \n",
    "        th.nn.Linear(\n",
    "            in_features=153, out_features=64, bias=True\n",
    "        ),\n",
    "        \n",
    "        th.nn.ReLU(),\n",
    "        \n",
    "        th.nn.Linear(\n",
    "            in_features=64, out_features=32, bias=True\n",
    "        ),\n",
    "        th.nn.ReLU(),\n",
    "        nn.LSTM(32, 16, bidirectional=True),\n",
    "        extract_tensor(),\n",
    "        th.nn.ReLU(),\n",
    "        \n",
    "        th.nn.Linear(\n",
    "            in_features=32, out_features=32, bias=True\n",
    "        ),\n",
    "        th.nn.ReLU(),\n",
    "        \n",
    "        th.nn.Linear(\n",
    "            in_features=32, out_features=16, bias=True\n",
    "        ),\n",
    "        th.nn.ReLU(),\n",
    "        \n",
    "        th.nn.Linear(\n",
    "            in_features=16, out_features=1, bias=True\n",
    "        ),\n",
    "        th.nn.ReLU(),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "de4982b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's detect and select the most appropriate device\n",
    "# (adapt it to your specific hardware needs: mps, tpu, ...)\n",
    "device: th.device = th.device(\n",
    "    \"cuda\" if th.cuda.is_available() and DEVICE_AUTODETECT else \"cpu\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eacd6a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NMRDataset(Dataset):\n",
    "    def __init__(self, maxLen = 250000, startSeed = 0):\n",
    "        self.maxLen = maxLen\n",
    "        self.startSeed = startSeed\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.maxLen\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        yy, res = nmr.generateRandomSpectrum(idx + self.startSeed)\n",
    "        isPk = np.full_like(yy[\"true\"], False)\n",
    "        for i in res:\n",
    "            isPk[i] = True\n",
    "        \n",
    "        #isPk[res[]] = True\n",
    "        return th.from_numpy(np.float32(yy[\"true\"])), isPk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "01daaaf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ML = 250000\n",
    "ML_test = 10000\n",
    "batch_size = 32\n",
    "train_set = NMRDataset(maxLen = ML)\n",
    "test_set = NMRDataset(maxLen = ML_test, startSeed = ML)\n",
    "\n",
    "train_loader: DataLoader = DataLoader(\n",
    "    dataset=train_set, batch_size=batch_size, shuffle=False\n",
    ")\n",
    "test_loader: DataLoader = DataLoader(\n",
    "    dataset=test_set,  batch_size=batch_size, shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "38a8027e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "Sequential                               [8192, 1]                 --\n",
       "├─Inception_variant: 1-1                 [8192, 153]               --\n",
       "│    └─Inception_piece: 2-1              [16, 8192]                --\n",
       "│    │    └─Conv1d: 3-1                  [1, 8193]                 3\n",
       "│    │    └─Conv1d: 3-2                  [16, 8192]                48\n",
       "│    └─Inception_piece: 2-2              [32, 8192]                --\n",
       "│    │    └─Conv1d: 3-3                  [1, 8195]                 5\n",
       "│    │    └─Conv1d: 3-4                  [32, 8192]                160\n",
       "│    └─Inception_piece: 2-3              [64, 8192]                --\n",
       "│    │    └─Conv1d: 3-5                  [1, 8199]                 9\n",
       "│    │    └─Conv1d: 3-6                  [64, 8192]                576\n",
       "│    └─Inception_piece: 2-4              [32, 8192]                --\n",
       "│    │    └─Conv1d: 3-7                  [1, 8207]                 17\n",
       "│    │    └─Conv1d: 3-8                  [32, 8192]                544\n",
       "│    └─Inception_piece: 2-5              [8, 8192]                 --\n",
       "│    │    └─Conv1d: 3-9                  [1, 8255]                 65\n",
       "│    │    └─Conv1d: 3-10                 [8, 8192]                 520\n",
       "│    └─MaxPool1d: 2-6                    [1, 8192]                 --\n",
       "│    └─Conv1d: 2-7                       [1, 8192]                 2\n",
       "├─ReLU: 1-2                              [8192, 153]               --\n",
       "├─Linear: 1-3                            [8192, 64]                9,856\n",
       "├─ReLU: 1-4                              [8192, 64]                --\n",
       "├─Linear: 1-5                            [8192, 32]                2,080\n",
       "├─ReLU: 1-6                              [8192, 32]                --\n",
       "├─LSTM: 1-7                              [8192, 32]                6,400\n",
       "├─extract_tensor: 1-8                    [8192, 32]                --\n",
       "├─ReLU: 1-9                              [8192, 32]                --\n",
       "├─Linear: 1-10                           [8192, 32]                1,056\n",
       "├─ReLU: 1-11                             [8192, 32]                --\n",
       "├─Linear: 1-12                           [8192, 16]                528\n",
       "├─ReLU: 1-13                             [8192, 16]                --\n",
       "├─Linear: 1-14                           [8192, 1]                 17\n",
       "├─ReLU: 1-15                             [8192, 1]                 --\n",
       "==========================================================================================\n",
       "Total params: 21,886\n",
       "Trainable params: 21,886\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.GIGABYTES): 1.79\n",
       "==========================================================================================\n",
       "Input size (MB): 0.03\n",
       "Forward/backward pass size (MB): 21.96\n",
       "Params size (MB): 0.09\n",
       "Estimated Total Size (MB): 22.08\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model: th.nn.Module = NMRSeq().to(device)\n",
    "summary(model, input_size=(1,8192))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5ab71a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer: th.optim.Optimizer = th.optim.Adam(\n",
    "    params=model.parameters(), lr=0.001, weight_decay=0\n",
    ")\n",
    "\n",
    "#lossCriterion = nn.MSELoss()\n",
    "lossCriterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a33475f2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d8c55537ae242079a509bf4379b577c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training epoch:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #0\n",
      "Training\n",
      "batch_idx: 0\n",
      "loss\n",
      "backwards\n",
      "batch_idx: 1\n",
      "loss\n",
      "backwards\n",
      "batch_idx: 2\n",
      "loss\n",
      "backwards\n",
      "batch_idx: 3\n",
      "loss\n",
      "backwards\n",
      "batch_idx: 4\n",
      "loss\n",
      "backwards\n",
      "batch_idx: 5\n",
      "loss\n",
      "backwards\n",
      "batch_idx: 6\n",
      "loss\n",
      "backwards\n",
      "batch_idx: 7\n",
      "loss\n",
      "backwards\n",
      "batch_idx: 8\n",
      "loss\n",
      "backwards\n",
      "batch_idx: 9\n",
      "loss\n",
      "backwards\n",
      "batch_idx: 10\n",
      "loss\n",
      "backwards\n",
      "batch_idx: 11\n",
      "loss\n",
      "backwards\n",
      "batch_idx: 12\n",
      "loss\n",
      "backwards\n",
      "batch_idx: 13\n",
      "loss\n",
      "backwards\n",
      "batch_idx: 14\n",
      "loss\n",
      "backwards\n",
      "batch_idx: 15\n",
      "loss\n",
      "backwards\n",
      "batch_idx: 16\n",
      "loss\n",
      "backwards\n",
      "batch_idx: 17\n",
      "loss\n",
      "backwards\n",
      "batch_idx: 18\n",
      "loss\n",
      "backwards\n",
      "batch_idx: 19\n",
      "loss\n",
      "backwards\n",
      "batch_idx: 20\n",
      "loss\n",
      "backwards\n",
      "batch_idx: 21\n",
      "loss\n",
      "backwards\n",
      "batch_idx: 22\n",
      "loss\n",
      "backwards\n",
      "batch_idx: 23\n",
      "loss\n",
      "backwards\n",
      "batch_idx: 24\n",
      "loss\n",
      "backwards\n",
      "batch_idx: 25\n",
      "loss\n",
      "backwards\n",
      "batch_idx: 26\n",
      "loss\n",
      "backwards\n",
      "batch_idx: 27\n",
      "loss\n",
      "backwards\n",
      "batch_idx: 28\n",
      "loss\n",
      "backwards\n",
      "batch_idx: 29\n",
      "loss\n",
      "backwards\n",
      "batch_idx: 30\n",
      "loss\n",
      "backwards\n",
      "batch_idx: 31\n",
      "loss\n",
      "backwards\n",
      "batch_idx: 32\n",
      "loss\n",
      "backwards\n",
      "batch_idx: 33\n",
      "loss\n",
      "backwards\n",
      "batch_idx: 34\n",
      "loss\n",
      "backwards\n",
      "batch_idx: 35\n",
      "loss\n",
      "backwards\n",
      "batch_idx: 36\n",
      "loss\n",
      "backwards\n",
      "batch_idx: 37\n",
      "loss\n",
      "backwards\n",
      "batch_idx: 38\n",
      "loss\n",
      "backwards\n",
      "batch_idx: 39\n",
      "loss\n",
      "backwards\n",
      "batch_idx: 40\n",
      "loss\n",
      "backwards\n",
      "batch_idx: 41\n",
      "loss\n",
      "backwards\n",
      "batch_idx: 42\n",
      "loss\n",
      "backwards\n",
      "batch_idx: 43\n",
      "loss\n",
      "backwards\n",
      "batch_idx: 44\n",
      "loss\n",
      "backwards\n",
      "batch_idx: 45\n",
      "loss\n",
      "backwards\n",
      "batch_idx: 46\n",
      "loss\n",
      "backwards\n",
      "batch_idx: 47\n",
      "loss\n",
      "backwards\n",
      "batch_idx: 48\n",
      "loss\n",
      "backwards\n",
      "batch_idx: 49\n",
      "loss\n",
      "backwards\n",
      "batch_idx: 50\n",
      "loss\n",
      "backwards\n",
      "batch_idx: 51\n",
      "loss\n",
      "backwards\n",
      "batch_idx: 52\n",
      "loss\n",
      "backwards\n",
      "batch_idx: 53\n",
      "loss\n",
      "backwards\n",
      "batch_idx: 54\n",
      "loss\n",
      "backwards\n",
      "batch_idx: 55\n",
      "loss\n",
      "backwards\n",
      "batch_idx: 56\n",
      "loss\n",
      "backwards\n",
      "batch_idx: 57\n",
      "loss\n",
      "backwards\n",
      "batch_idx: 58\n",
      "loss\n",
      "backwards\n",
      "batch_idx: 59\n",
      "loss\n",
      "backwards\n",
      "batch_idx: 60\n",
      "loss\n",
      "backwards\n",
      "batch_idx: 61\n",
      "loss\n",
      "backwards\n",
      "batch_idx: 62\n",
      "loss\n",
      "backwards\n",
      "batch_idx: 63\n",
      "loss\n",
      "backwards\n",
      "batch_idx: 64\n",
      "loss\n",
      "backwards\n",
      "batch_idx: 65\n",
      "loss\n",
      "backwards\n",
      "batch_idx: 66\n",
      "loss\n",
      "backwards\n",
      "batch_idx: 67\n",
      "loss\n",
      "backwards\n",
      "batch_idx: 68\n",
      "loss\n",
      "backwards\n",
      "batch_idx: 69\n",
      "loss\n",
      "backwards\n",
      "batch_idx: 70\n",
      "loss\n",
      "backwards\n",
      "batch_idx: 71\n",
      "loss\n",
      "backwards\n",
      "batch_idx: 72\n",
      "loss\n",
      "backwards\n",
      "batch_idx: 73\n",
      "loss\n",
      "backwards\n",
      "batch_idx: 74\n",
      "loss\n",
      "backwards\n",
      "batch_idx: 75\n",
      "loss\n",
      "backwards\n",
      "batch_idx: 76\n",
      "loss\n",
      "backwards\n",
      "batch_idx: 77\n",
      "loss\n",
      "backwards\n",
      "batch_idx: 78\n",
      "loss\n",
      "backwards\n",
      "batch_idx: 79\n",
      "loss\n",
      "backwards\n",
      "batch_idx: 80\n",
      "loss\n",
      "backwards\n",
      "batch_idx: 81\n",
      "loss\n",
      "backwards\n",
      "batch_idx: 82\n",
      "loss\n",
      "backwards\n",
      "batch_idx: 83\n",
      "loss\n",
      "backwards\n",
      "batch_idx: 84\n",
      "loss\n",
      "backwards\n",
      "batch_idx: 85\n",
      "loss\n",
      "backwards\n",
      "batch_idx: 86\n",
      "loss\n",
      "backwards\n",
      "batch_idx: 87\n",
      "loss\n",
      "backwards\n",
      "batch_idx: 88\n",
      "loss\n",
      "backwards\n",
      "batch_idx: 89\n",
      "loss\n",
      "backwards\n",
      "batch_idx: 90\n",
      "loss\n",
      "backwards\n",
      "batch_idx: 91\n",
      "loss\n",
      "backwards\n",
      "batch_idx: 92\n",
      "loss\n",
      "backwards\n",
      "batch_idx: 93\n",
      "loss\n",
      "backwards\n",
      "batch_idx: 94\n",
      "loss\n",
      "backwards\n",
      "batch_idx: 95\n",
      "loss\n",
      "backwards\n",
      "batch_idx: 96\n",
      "loss\n",
      "backwards\n",
      "batch_idx: 97\n",
      "loss\n",
      "backwards\n",
      "batch_idx: 98\n",
      "loss\n",
      "backwards\n",
      "batch_idx: 99\n",
      "loss\n",
      "backwards\n",
      "batch_idx: 100\n",
      "loss\n",
      "backwards\n",
      "batch_idx: 101\n",
      "loss\n",
      "backwards\n",
      "batch_idx: 102\n",
      "loss\n",
      "backwards\n",
      "batch_idx: 103\n",
      "loss\n",
      "backwards\n",
      "batch_idx: 104\n",
      "loss\n",
      "backwards\n",
      "batch_idx: 105\n",
      "loss\n",
      "backwards\n",
      "batch_idx: 106\n",
      "loss\n",
      "backwards\n",
      "batch_idx: 107\n",
      "loss\n",
      "backwards\n",
      "batch_idx: 108\n",
      "loss\n",
      "backwards\n",
      "batch_idx: 109\n",
      "loss\n",
      "backwards\n",
      "batch_idx: 110\n",
      "loss\n",
      "backwards\n",
      "batch_idx: 111\n",
      "loss\n",
      "backwards\n",
      "batch_idx: 112\n",
      "loss\n",
      "backwards\n",
      "batch_idx: 113\n",
      "loss\n",
      "backwards\n",
      "batch_idx: 114\n",
      "loss\n",
      "backwards\n",
      "batch_idx: 115\n",
      "loss\n",
      "backwards\n",
      "batch_idx: 116\n",
      "loss\n",
      "backwards\n",
      "batch_idx: 117\n",
      "loss\n",
      "backwards\n",
      "batch_idx: 118\n",
      "loss\n",
      "backwards\n",
      "batch_idx: 119\n",
      "loss\n",
      "backwards\n",
      "batch_idx: 120\n",
      "loss\n",
      "backwards\n",
      "batch_idx: 121\n",
      "loss\n",
      "backwards\n",
      "batch_idx: 122\n",
      "loss\n",
      "backwards\n",
      "batch_idx: 123\n",
      "loss\n",
      "backwards\n",
      "batch_idx: 124\n",
      "loss\n",
      "backwards\n",
      "batch_idx: 125\n",
      "loss\n",
      "backwards\n",
      "batch_idx: 126\n",
      "loss\n",
      "backwards\n",
      "batch_idx: 127\n",
      "loss\n",
      "backwards\n",
      "batch_idx: 128\n",
      "loss\n",
      "backwards\n",
      "batch_idx: 129\n",
      "loss\n",
      "backwards\n",
      "batch_idx: 130\n",
      "loss\n",
      "backwards\n",
      "batch_idx: 131\n",
      "loss\n",
      "backwards\n",
      "batch_idx: 132\n",
      "loss\n",
      "backwards\n",
      "batch_idx: 133\n",
      "loss\n",
      "backwards\n",
      "batch_idx: 134\n",
      "loss\n",
      "backwards\n",
      "batch_idx: 135\n",
      "loss\n",
      "backwards\n",
      "batch_idx: 136\n",
      "loss\n",
      "backwards\n",
      "batch_idx: 137\n",
      "loss\n",
      "backwards\n",
      "batch_idx: 138\n",
      "loss\n",
      "backwards\n",
      "batch_idx: 139\n",
      "loss\n",
      "backwards\n",
      "batch_idx: 140\n",
      "loss\n",
      "backwards\n",
      "batch_idx: 141\n",
      "loss\n",
      "backwards\n",
      "batch_idx: 142\n",
      "loss\n",
      "backwards\n",
      "batch_idx: 143\n",
      "loss\n",
      "backwards\n",
      "batch_idx: 144\n",
      "loss\n",
      "backwards\n",
      "batch_idx: 145\n",
      "loss\n",
      "backwards\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 17\u001b[39m\n\u001b[32m     15\u001b[39m \u001b[38;5;28mprint\u001b[39m (\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mTraining\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     16\u001b[39m \u001b[38;5;66;03m# Loop over data\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatched_datapoint\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     18\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mprint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mbatch_idx: \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mbatch_idx\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     19\u001b[39m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatched_datapoint\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pythonenvs/deeplearning/lib/python3.13/site-packages/torch/utils/data/dataloader.py:732\u001b[39m, in \u001b[36m_BaseDataLoaderIter.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    729\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    730\u001b[39m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[32m    731\u001b[39m     \u001b[38;5;28mself\u001b[39m._reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m732\u001b[39m data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    733\u001b[39m \u001b[38;5;28mself\u001b[39m._num_yielded += \u001b[32m1\u001b[39m\n\u001b[32m    734\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    735\u001b[39m     \u001b[38;5;28mself\u001b[39m._dataset_kind == _DatasetKind.Iterable\n\u001b[32m    736\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    737\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._num_yielded > \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called\n\u001b[32m    738\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pythonenvs/deeplearning/lib/python3.13/site-packages/torch/utils/data/dataloader.py:788\u001b[39m, in \u001b[36m_SingleProcessDataLoaderIter._next_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    786\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    787\u001b[39m     index = \u001b[38;5;28mself\u001b[39m._next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m788\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m    789\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._pin_memory:\n\u001b[32m    790\u001b[39m         data = _utils.pin_memory.pin_memory(data, \u001b[38;5;28mself\u001b[39m._pin_memory_device)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pythonenvs/deeplearning/lib/python3.13/site-packages/torch/utils/data/_utils/fetch.py:52\u001b[39m, in \u001b[36m_MapDatasetFetcher.fetch\u001b[39m\u001b[34m(self, possibly_batched_index)\u001b[39m\n\u001b[32m     50\u001b[39m         data = \u001b[38;5;28mself\u001b[39m.dataset.__getitems__(possibly_batched_index)\n\u001b[32m     51\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m52\u001b[39m         data = [\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[32m     53\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     54\u001b[39m     data = \u001b[38;5;28mself\u001b[39m.dataset[possibly_batched_index]\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 10\u001b[39m, in \u001b[36mNMRDataset.__getitem__\u001b[39m\u001b[34m(self, idx)\u001b[39m\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, idx):\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m     yy, res = \u001b[43mnmr\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgenerateRandomSpectrum\u001b[49m\u001b[43m(\u001b[49m\u001b[43midx\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstartSeed\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     11\u001b[39m     isPk = np.full_like(yy[\u001b[33m\"\u001b[39m\u001b[33mtrue\u001b[39m\u001b[33m\"\u001b[39m], \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m     12\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m res:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/notebooks/NMR/NMRAux.py:144\u001b[39m, in \u001b[36mgenerateRandomSpectrum\u001b[39m\u001b[34m(seed)\u001b[39m\n\u001b[32m    141\u001b[39m SNR = yy/(maxNoise/\u001b[32m2\u001b[39m)      \n\u001b[32m    142\u001b[39m yyReg = yy * peakShrinking(SNR)\n\u001b[32m--> \u001b[39m\u001b[32m144\u001b[39m yyFiltered = \u001b[43mdynamicScaleFiltering\u001b[49m\u001b[43m(\u001b[49m\u001b[43myy\u001b[49m\u001b[43m)\u001b[49m  \n\u001b[32m    146\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m'''\u001b[39;00m\n\u001b[32m    147\u001b[39m \u001b[33;03m\u001b[39;00m\n\u001b[32m    148\u001b[39m \u001b[33;03m    \u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    157\u001b[39m \u001b[33;03mretStats.append({\"xPks\": xPks, \"yPks\":yPks, \"wPks\": wPks, \"peaks\": peaks})\u001b[39;00m\n\u001b[32m    158\u001b[39m \u001b[33;03m'''\u001b[39;00m\n\u001b[32m    161\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[33m\"\u001b[39m\u001b[33mpure\u001b[39m\u001b[33m\"\u001b[39m: yy, \u001b[33m\"\u001b[39m\u001b[33mtrue\u001b[39m\u001b[33m\"\u001b[39m: yy + noise, \u001b[33m\"\u001b[39m\u001b[33mfiltered\u001b[39m\u001b[33m\"\u001b[39m: yyFiltered, \u001b[33m\"\u001b[39m\u001b[33mreg\u001b[39m\u001b[33m\"\u001b[39m: yyReg}, peaks\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/notebooks/NMR/NMRAux.py:48\u001b[39m, in \u001b[36mdynamicScaleFiltering\u001b[39m\u001b[34m(yy)\u001b[39m\n\u001b[32m     46\u001b[39m S_max = maximum_filter1d(yy, k)\n\u001b[32m     47\u001b[39m S_min = minimum_filter1d(yy, k)\n\u001b[32m---> \u001b[39m\u001b[32m48\u001b[39m S_min_g = \u001b[43mgaussian_filter1d\u001b[49m\u001b[43m(\u001b[49m\u001b[43mS_min\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmirror\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     49\u001b[39m S_max_g = gaussian_filter1d(S_max, k, mode = \u001b[33m\"\u001b[39m\u001b[33mmirror\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     50\u001b[39m yy_final += (yy - S_min_g) / (S_max_g - S_min_g)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pythonenvs/deeplearning/lib/python3.13/site-packages/scipy/ndimage/_filters.py:753\u001b[39m, in \u001b[36mgaussian_filter1d\u001b[39m\u001b[34m(input, sigma, axis, order, output, mode, cval, truncate, radius)\u001b[39m\n\u001b[32m    751\u001b[39m \u001b[38;5;66;03m# Since we are calling correlate, not convolve, revert the kernel\u001b[39;00m\n\u001b[32m    752\u001b[39m weights = _gaussian_kernel1d(sigma, order, lw)[::-\u001b[32m1\u001b[39m]\n\u001b[32m--> \u001b[39m\u001b[32m753\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcorrelate1d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pythonenvs/deeplearning/lib/python3.13/site-packages/scipy/ndimage/_filters.py:610\u001b[39m, in \u001b[36mcorrelate1d\u001b[39m\u001b[34m(input, weights, axis, output, mode, cval, origin)\u001b[39m\n\u001b[32m    606\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m'\u001b[39m\u001b[33mInvalid origin; origin must satisfy \u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m    607\u001b[39m                      \u001b[33m'\u001b[39m\u001b[33m-(len(weights) // 2) <= origin <= \u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m    608\u001b[39m                      \u001b[33m'\u001b[39m\u001b[33m(len(weights)-1) // 2\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m    609\u001b[39m mode = _ni_support._extend_mode_to_code(mode)\n\u001b[32m--> \u001b[39m\u001b[32m610\u001b[39m \u001b[43m_nd_image\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcorrelate1d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    611\u001b[39m \u001b[43m                      \u001b[49m\u001b[43morigin\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    612\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m output\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "EPOCHS = 100\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "eval_losses = []\n",
    "eval_acc = []\n",
    "test_acc = []\n",
    "\n",
    "# Loop over epochs\n",
    "for epoch in trange(EPOCHS, desc=\"Training epoch\"):\n",
    "    \n",
    "    print (f\"Epoch #{epoch}\")\n",
    "\n",
    "    model.train()  # Remember to set the model in training mode before actual training\n",
    "\n",
    "    print (f\"Training\")\n",
    "    # Loop over data\n",
    "    for batch_idx, batched_datapoint in enumerate(train_loader):\n",
    "        print(f\"batch_idx: {batch_idx}\")\n",
    "        x, y = batched_datapoint\n",
    "        x, y = x.to(device), y.to(device)\n",
    "\n",
    "        # Forward pass + loss computation\n",
    "        yhat = model(x)\n",
    "        yhat = th.transpose(yhat,0,1)\n",
    "        loss = lossCriterion(yhat, y)\n",
    "        print(\"loss\")\n",
    "\n",
    "        # Zero-out past gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        print(\"backwards\")\n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "\n",
    "        # Update model parameters\n",
    "        optimizer.step()\n",
    "\n",
    "    model.eval()  # Remember to set the model in evaluation mode before evaluating it\n",
    "    print (f\"Eval\")\n",
    "\n",
    "    # Since we are just evaluating the model, we don't need to compute gradients\n",
    "    with th.no_grad():\n",
    "        # ... by looping over training data again\n",
    "        for _, batched_datapoint_e in enumerate(train_loader):\n",
    "            x_e, y_e = batched_datapoint_e\n",
    "            x_e, y_e = x_e.to(device), y_e.to(device)\n",
    "            modeltarget_e = model(x_e)\n",
    "            ypred_e = th.argmax(modeltarget_e, dim=1, keepdim=True)\n",
    "            trackingmetric += lossCriterion(modeltarget_e, y_e).item()\n",
    "            trackingcorrect += ypred_e.eq(y_e.view_as(ypred_e)).sum().item()\n",
    "            num_elem += x_e.shape[0]\n",
    "        eval_losses.append(trackingmetric / num_elem)\n",
    "        eval_acc.append(trackingcorrect / num_elem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef79fea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "00dd96ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NMRModule(th.nn.Module):\n",
    "    def __init__(self, cls_out: int = 10) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        self.inception = Inception_variant(0)\n",
    "        \n",
    "        self.tddb1 = nn.Conv1d(1, \n",
    "                              64,#num_of_output_channels, \n",
    "                              (158, 1)) #num_of_input_channels\n",
    "        \n",
    "        self.tddb2 = nn.Conv1d(1, \n",
    "                              32,#num_of_output_channels, \n",
    "                              (64,  1)) #num_of_input_channels\n",
    "        \n",
    "        self.bdlstm = th.nn.LSTM(64, 16, bidirectional=True)\n",
    "        \n",
    "        self.tdda1 = nn.Conv1d(1, \n",
    "                              32,#num_of_output_channels, \n",
    "                              (16, 1))\n",
    "        \n",
    "        self.tdda2 = nn.Conv1d(1, \n",
    "                              16,#num_of_output_channels, \n",
    "                              (32, 1)) #num_of_input_channels\n",
    "        \n",
    "        self.tdda3 = nn.Conv1d(1, \n",
    "                              5,#num_of_output_channels, \n",
    "                              (16, 1)) #num_of_input_channels\n",
    "        \n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        \n",
    "        x_ = self.inception(x)  # Apply first linear transformation\n",
    "        x_ = th.nn.functional.relu(x_)  # Relu Not Necessary?\n",
    "        \n",
    "        x_ = self.tddb1(x_)\n",
    "        x_ = relu(x_)\n",
    "        \n",
    "        x_ = self.tddb2(x_)\n",
    "        x_ = relu(x_)\n",
    "        \n",
    "        x_ = self.bdlstm(x_)\n",
    "        x_ = relu(x_)\n",
    "        \n",
    "        x_ = self.tdd11(x_)\n",
    "        x_ = relu(x_)\n",
    "        \n",
    "        x_ = self.tdda2(x_)\n",
    "        x_ = relu(x_)\n",
    "        \n",
    "        x_ = self.tdda3(x_)\n",
    "        x_ = relu(x_)\n",
    "        \n",
    "        \n",
    "        # N.B.: outputs are [-inf, +inf]; e.g. to be used as logits\n",
    "        return x_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deeplearning",
   "language": "python",
   "name": "deeplearning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
